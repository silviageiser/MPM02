---
title: "Machine_Learning_Algorithms_Documentation"
author: "Geiser, Gruen, Hefti, Kuster"
date: "08/01/2021"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
    toc_float: yes
---



# Machine Learning Algorithms

## Dataset - German Housing Data

We cleaned the origin data set: Variable rooms, bathrooms, bedrooms, floors, garages, Year_built, Year_renovated changed from decimal to integer.

We created a subset with buildings up to 20 rooms for our analysis and rounded .5 room numbers to integers.
We transformed the categories in the variable Energy_source and Garagetype.

**Load of the cleaned dataset**

```{r}
data <- read.csv('german_housing_cleaned.csv',header =T, encoding='UTF-8')
head(data)
```
# Analysis of variables

**Inspection of all variables**
```{r}
str(data)
summary(data)
colnames(data)
```


**Analysis of the distribution of the variables: 'Price', 'Living_space', 'Rooms' and 'Lot'**
```{r}
par(mfrow = c(2,2))

#Price
plot(density(data$Price))

#Living_space
plot(density(data$Living_space))

#Rooms
hist(data$Rooms)

#Lot
plot(density(data$Lot))
```
Result: The variables are right skewed


Therefore we will use the Log Transformation of the variables 'Price', 'Living_space', 'Rooms', 'Lot' to get a nearly normal distribution
``` {r}
par(mfrow = c(2,2))

#Price
price.log <- density(log(data$Price))
plot(price.log)

#Living_space
living.log <- density(log(data$Living_space))
plot(living.log)

#Rooms
rooms.log <- log(data$Rooms)
hist(rooms.log)

#Lot
lot.log <- density(log(data$Lot))
plot(lot.log)
```


# WEEK 1

## Linear Models

**Data Visualisation and Simple linear regression**


the variables Price, Living_space and Rooms are checked for na values
```{r, message=F, error=F, warning=F}
options(scipen=999) #block scientific notation
library(ggplot2)
attach(data)
any(is.na(Price))
any(is.na(Living_space))
any(is.na(Rooms))
```


We plot the response variable "Price" against the predictor "Living_Space" to get a first impression and grahical analysis.
```{r, message=F}
#Living_space
ggplot(data, aes(log(Living_space), log(Price))) + geom_point() + geom_smooth(method = lm, se = T, color = 'red') + ggtitle('Scatterplot with regression line for log(Price) against log(Living_space)')
```

Fitting a Simple Linear regression of log(Price) against log(Living_space)
```{r}
#linear model
lm.log.price_living <- lm(log(Price) ~ log(Living_space))
summary(lm.log.price_living)

#estimated regression coefficients
living.coefs <- coef(lm.log.price_living)
living.coefs

#p-values
summary(lm.log.price_living)$coefficients
```

Linear regression of log(Price) against log(Living_space) and Type
```{r}
lm.log.price_living_type <- lm(log(Price) ~ log(Living_space) + Type)
summary(lm.log.price_living_type)
```
It seems to be a positive relationship between these two variables. More livingspace seems to have a higher price. So we fit a simple regression model to the data.

Before we interpret the intercept and the second coefficient, the slope, we exponentiate the values. The results are: For the intercept exp(8.17522)= 3551.84 and the slope exp(0.9028)=2.47

Therefore the interpretation would be: With a livingspace of 0 the price would be 3551.84 EURO and with each unit increase of the livingspace the price increase by 2.47 EURO which does not make much sense.

Anyway the p-value is very small therefore we have a string evidence that the slope for livingspace is not flat.


In an next step we examine the data set graphically and consider again "Price" as response variable but as predictor "Rooms" and we fit the model again with a simple linear regression.
```{r,message=F}
#Rooms
ggplot(data, aes(Rooms,Price)) + geom_point()+ geom_smooth(method = lm, se = F, color= 'red') +
scale_x_continuous(breaks = rep(1:20,len=20)) + ggtitle('Plot of Price against Rooms with regression line in red')

lm.log.price_rooms <- lm(log(Price) ~ log(Rooms))
summary(lm.log.price_rooms)
```

Now we are modelling a linear regression with dependent variable 'Price' and the categorical variable "Type" as independent variable. First we visualize the variable 'Type' with a boxplot with and one without outliers.
```{r}
types.box.with_outlier <- ggplot(data, aes(x=Type, y=log(Price))) + geom_boxplot(outlier.colour = 'red')+ theme(axis.text.x = element_text(angle = 90)) + ggtitle('Boxplots of log(Price) against Types with outliers in red')
plot(types.box.with_outlier)

types.box.no_outlier <- ggplot(data, aes(x=Type, y=log(Price))) + geom_boxplot(outlier.shape = NA)+ theme(axis.text.x = element_text(angle = 90)) + ggtitle('Boxplots of log(Price) against Types without outliers')
plot(types.box.no_outlier)

lm.type <- lm(log(Price) ~ Type)
summary(lm.type)
```

Testing categorical variable (Furnishing_quality)and comparing by F-test 
```{r}
furnish.box.with_outlier <- ggplot(data, aes(x=Furnishing_quality, y=log(Price))) + geom_boxplot(outlier.colour = 'red')+ theme(axis.text.x = element_text(angle = 90)) + ggtitle('Boxplots of log(Price) against Furnishing Quality with outliers in red')
plot(furnish.box.with_outlier)

furnish.box.no_outlier <- ggplot(data, aes(x=Furnishing_quality, y=log(Price))) + geom_boxplot(outlier.shape = NA)+ theme(axis.text.x = element_text(angle = 90)) + ggtitle('Boxplots of log(Price) against Furnishing Quality without outliers')
plot(furnish.box.no_outlier)

lm.furnishing <- lm(log(Price) ~ Furnishing_quality)
summary(lm.furnishing)

lm.furnishing1 <- lm(log(Price) ~ 1)
summary(lm.furnishing1)

anova.furnishing <- anova(lm.furnishing1, lm.furnishing)
summary(anova.furnishing)
```


**Multiple linear regression**

Adding more categorical variables to the testing above
```{r}
lm.furnishing2 <- update(lm.furnishing,. ~ . + Type + Condition)
formula(lm.furnishing2)
drop1(lm.furnishing2, test = "F")
```

Check the interaction between variables
```{r}
lm.interact <- lm(log(Price) ~ Type * Living_space)
summary(lm.interact)
```


# WEEK 2

## model nonlinearity


Polynomials
Graphical analysis
```{r, message = F, error = F}
library(mgcv)
attach(data)
library(ggplot2)
``` 

```{r, message = F}
#log(Price) ~ Rooms
gg.PriceRooms <- ggplot(data,
mapping = aes(y = log(Price),
x = Rooms)) +
geom_point()
gg.PriceRooms +
geom_smooth() +
scale_x_continuous(breaks = rep(1:20,len=20))


gam.1 <- gam(log(Price) ~ s(Rooms))
summary(gam.1)


plot(gam.1, residuals = TRUE, cex = 2)
```

log(Prices) ~ log(Rooms)
```{r, message = F}
#log(Rooms)
gg.PriceRooms <- ggplot(data,
mapping = aes(y = log(Price),
x = log(Rooms))) +
geom_point()
gg.PriceRooms +
geom_smooth() 

gam.2 <- gam(log(Price) ~ s(Rooms))
summary(gam.2)
plot(gam.2, residuals = TRUE, cex = 2)


gg.PriceLiving <- ggplot(data,
mapping = aes(y = log(Price),
x = log(Living_space))) +
geom_point()
gg.PriceLiving +
geom_smooth()

gam.3 <- gam(log(Price) ~ log(Living_space) +
s(Rooms) + s(Garages),
data = data)
summary(gam.3)
plot(gam.3, residuals = TRUE, select = 1)
```


```{r, message = F}
gg.LotPrice <- ggplot(data = data,
mapping = aes(y = log(Lot),
x = log(Price))) +
geom_point()
gg.LotPrice +
geom_smooth(method = 'gam')
```


# WEEK 3

## GLM

**Possion Model**

```{r}
glm.rooms <- glm(Rooms ~ Type,
family = "poisson",
data = data)

summary(glm.rooms)

```

```{r}
set.seed(99)
sim.data.rooms.Poisson <- simulate(glm.rooms)
##
NROW(sim.data.rooms.Poisson)

head(sim.data.rooms.Poisson)
tail(sim.data.rooms.Poisson)

```
Visualisierung ;)
``` {r}
ggplot(mapping = aes(y = sim.data.rooms.Poisson$sim_1,
x = data$Type)) +
geom_boxplot() +
geom_hline(yintercept = 0) +
ylab("simulated no. of rooms\n(assuming Poisson dist)") +
xlab("type")
```



``` {r}


#install.packages('mltools')
library(mltools)

# Resulting bins have an equal number of observations in each group
data[, "wt2"] <- bin_data(data$Price, bins=4, binType = "quantile")

# Resulting bins are equally spaced from min to max
data[, "wt3"] <- bin_data(data$Price, bins=4, binType = "explicit")

# Or if you'd rather define the bins yourself
data[, "wt4"] <- bin_data(data$Price, bins=c(-Inf, 250, 322, Inf), binType = "explicit")
head(data)
```

``` {r}
glm.roomswt2 <- glm(Rooms ~ wt2,
family = "poisson",
data = data)

summary(glm.roomswt2)
```
``` {r}
set.seed(99)
sim.data.rooms.Poissonwt2 <- simulate(glm.roomswt2)
##
NROW(sim.data.rooms.Poissonwt2)

head(sim.data.rooms.Poissonwt2)
tail(sim.data.rooms.Poissonwt2)
```
``` {r}
library(ggplot2)
ggplot(mapping = aes(y = sim.data.rooms.Poissonwt2$sim_1,
x = data$wt2)) +
geom_boxplot() +
geom_hline(yintercept = 0) +
ylab("simulated no. of rooms\n(assuming Poisson dist)") +
xlab("Groups")
```
Binary Model
Let’s fit a binary model

``` {r}
data$MillionYes <- ifelse(data$Price > 1000000, 1, 0)
data$MillionYes

ggplot(data = data,
mapping = aes(y = MillionYes,
x = log(Living_space))) +
geom_point()
```
Let’s fit a logistic regression model and add fit to the this graph

``` {r}
ggplot(data = data,
       mapping = aes(y = MillionYes,
                     x = log(Living_space))) + 
  geom_point() +
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 
```



Let's try something else



















