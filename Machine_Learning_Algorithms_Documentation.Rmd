---
output:
  html_document: default
  'html_document: default': default
---
```` Markdown
---
title: "Machine_Learning_Algorithms_Documentation"
author: "Geiser, Gruen, Hefti, Kuster"
date: "11/11/2020"
output: html_document: default
---



**Machine Learning Algorithms**

**Dataset - German Housing Data**

load cleaned dataset

```{r}
# load dataset
data <- read.csv('germany_housing_cleaned_v03.csv',header =T, sep=';', encoding='UTF-8')

# rename Price variable
names(data)[names(data) == "X.U.FEFF.Price"] <- "Price"
head(data)

```
```{r}
str(data)
colnames(data)
```

``` {r}
# We look at the distribution of our price variable. Highly right skewed.
d <- density(data$Price)
plot(d)
```

``` {r}
#log trasnform our price var to get more normale distributed var.
d.log <- density(log(data$Price))
plot(d.log)
```

``` {r}
# Some Variable are highly right skewed.
#Price, Living_space, lot, rooms and more. We will use the logtransformed datain our analysis.
d.density <- density(log(data$Living_space))
plot(d.density)
hist(log(data$Rooms))
```
``` {r}
# Some Variable are highly right skewed.
#Price, Living_space, lot, rooms and more. We will use the logtransformed datain our analysis.
d.density <- density(log(data$Living_space))
plot(d.density)
hist(log(data$Rooms))
```

**WEEK 1**

**Linear Models**

Simple linear regression

Data Visualisation

Plot Price ~ Living_Space
```{r}
options(scipen=999) #block scientific notation

library(ggplot2)


#Living Space
ggplot(data, aes(log(Living_space), log(Price))) + geom_point() + geom_smooth(method = lm, se = F, color = 'red')
#ggplot(data, aes(log(Living_space), log(Lot))) + geom_smooth(method = lm, se =F, color = 'red')

```
``` {r}
lm.log.price_living <- lm(log(data$Price) ~ log(data$Living_space))
print(summary(lm.log.price_living))
```

Data Visualisation

Plot Price ~ Rooms

```` {r}
library(ggplot2)
#Rooms
ggplot(data, aes(log(Rooms), log(Price))) + geom_point()+ geom_smooth(method = lm, se = F, color= 'red')
ggplot(data, aes(log(Rooms), log(Price))) + geom_point(aes(size=Living_space, colour = factor(State)))
ggplot(data, aes(log(Rooms), log(Price))) + geom_bin2d(bins = 30)

lm.log.price_rooms <- lm(log(data$Price) ~ log(data$Rooms))
print(summary(lm.log.price_rooms))
````

``` {r}
#Living Space
ggplot(data, aes(log(Price), log(Lot))) + geom_point() + geom_smooth(method = lm, se = F, color = 'red')
#ggplot(data, aes(log(Living_space), log(Lot))) + geom_smooth(method = lm, se =F, color = 'red')
```

``` {r}
#lm.log.Lot_Price <- lm(log(data$Lot) ~ log(data$Price))
#print(summary(lm.log.Lot_Price))
```


```{r}

# use ggplot instead - to do
#par(mfrow=c(2,1))
#boxplot(log(data$Price) ~ Type, main = 'Price ~ Type plotted with outliers')
#boxplot(log(data$Price) ~ Type, main = 'Price ~ Type plotted WITHOUT outliers', outline=FALSE)
```


```{r}
lm.type_rooms <- lm(Price ~ Type, data = data)
summary(lm.type_rooms)
```
**WEEK 2**

**model nonlinearity**

Polynomials
Graphical analysis
``` {r}
gg.PriceRooms <- ggplot(data = data,
mapping = aes(y = log(Price),
x = Rooms)) +
geom_point()
gg.PriceRooms +
geom_smooth()

```
``` {r}
gg.PriceRooms <- ggplot(data = data,
mapping = aes(y = log(Price),
x = log(Rooms))) +
geom_point()
gg.PriceRooms +
geom_smooth()

```

``` {r}
gg.LotPrice <- ggplot(data = data,
mapping = aes(y = log(Lot),
x = log(Price))) +
geom_point()
gg.LotPrice +
geom_smooth()

```

```{r}
library(mgcv)
gam.1 <- gam(log(Price) ~ s(Rooms), data = data)
summary(gam.1)


plot(gam.1, residuals = TRUE, cex = 2)

```
``` {r}
gam.2 <- gam(log(Price) ~ log(Living_space) +
s(Rooms) + s(Garages),
data = data)
summary(gam.2)


```
``` {r}
plot(gam.2, residuals = TRUE, select = 1)

```


**WEEK 3**

**GLM**

Possion Model

```{r}
glm.rooms <- glm(Rooms ~ Type,
family = "poisson",
data = data)

summary(glm.rooms)

```

```{r}
set.seed(99)
sim.data.rooms.Poisson <- simulate(glm.rooms)
##
NROW(sim.data.rooms.Poisson)

head(sim.data.rooms.Poisson)
tail(sim.data.rooms.Poisson)

```
Visualisierung ;)
``` {r}
ggplot(mapping = aes(y = sim.data.rooms.Poisson$sim_1,
x = data$Type)) +
geom_boxplot() +
geom_hline(yintercept = 0) +
ylab("simulated no. of rooms\n(assuming Poisson dist)") +
xlab("type")
```



``` {r}


#install.packages('mltools')
library(mltools)

# Resulting bins have an equal number of observations in each group
data[, "wt2"] <- bin_data(data$Price, bins=4, binType = "quantile")

# Resulting bins are equally spaced from min to max
data[, "wt3"] <- bin_data(data$Price, bins=4, binType = "explicit")

# Or if you'd rather define the bins yourself
data[, "wt4"] <- bin_data(data$Price, bins=c(-Inf, 250, 322, Inf), binType = "explicit")
# Resulting bins are equally spaced from min to max
data[, "wt5"] <-bin_data(data$Price, bins=c(-Inf, 600000, Inf), binType = "explicit")

head(data)
```

``` {r}
glm.roomswt2 <- glm(Rooms ~ wt2,
family = "poisson",
data = data)

summary(glm.roomswt2)
```
``` {r}
set.seed(99)
sim.data.rooms.Poissonwt2 <- simulate(glm.roomswt2)
##
NROW(sim.data.rooms.Poissonwt2)

head(sim.data.rooms.Poissonwt2)
tail(sim.data.rooms.Poissonwt2)
```
``` {r}
library(ggplot2)
ggplot(mapping = aes(y = sim.data.rooms.Poissonwt2$sim_1,
x = data$wt2)) +
geom_boxplot() +
geom_hline(yintercept = 0) +
ylab("simulated no. of rooms\n(assuming Poisson dist)") +
xlab("Groups")
```
Binary Model
Let’s fit a binary model

``` {r}
data$MillionYes <- ifelse(data$Price > 1000000, 1, -1)
data$MillionYes

ggplot(data = data,
mapping = aes(y = MillionYes,
x = log(Living_space))) +
geom_point()
```
Let’s fit a logistic regression model and add fit to the this graph

``` {r}
ggplot(data = data,
       mapping = aes(y = MillionYes,
                     x = log(Living_space))) + 
  geom_point() +
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 
```



Let's try something else



**WEEK 4**

**Support Vector Machines**
```{r}
data$wt5 <- factor(ifelse(data$wt5 > 600000, 1, -1))
data['MillionYes'] = as.factor(data$MillionYes)
str(data)

```

``` {r}
# Load ggplot2
library(ggplot2)

# Plot x2 vs. x1, colored by y
scatter_plot<- ggplot(data = data, aes(x = Living_space, y = Year_built, color = wt2
                                       
                              )) + 
    # Add a point layer
    geom_point() + 
    scale_color_manual(values = c("red", "blue","green", "purple")) +
    # Specify equal coordinates
    coord_equal()
 
scatter_plot  
```
```{r}

x1 <- scales::rescale(data$Living_space, to=c(0,1))
x2 <- scales::rescale(data$Year_built, to=c(0,1))
x3 <- scales::rescale(data$Rooms, to=c(0,1))
x4 <- scales::rescale(data$Lot, to=c(0,1))

```

``` {r}
# Load ggplot2
library(ggplot2)

# Plot x2 vs. x1, colored by y
scatter_plot<- ggplot(data = data, aes(x = x1, y = x2, color = wt2
                                       
                              )) + 
    # Add a point layer
    geom_point() + 
    scale_color_manual(values = c("red", "blue","green", "purple")) +
    # Specify equal coordinates
    coord_equal()
 
scatter_plot  
```



``` {r}
# Load ggplot2
library(ggplot2)

# Plot x2 vs. x1, colored by y
scatter_plot<- ggplot(data = data, aes(x = x1, y = x2, color = MillionYes
                                       
                              )) + 
    # Add a point layer
    geom_point() + 
    scale_color_manual(values = c("red", "blue")) +
    # Specify equal coordinates
    coord_equal()
 
scatter_plot  
```


``` {r}
# Load ggplot2
library(ggplot2)

# Plot x2 vs. x1, colored by y
scatter_plot<- ggplot(data = data, aes(x = x1, y = x3, color = wt5
                                       
                              )) + 
    # Add a point layer
    geom_point() + 
    scale_color_manual(values = c("red", "blue")) +
    # Specify equal coordinates
    coord_equal()
 
scatter_plot  
```

``` {r}
# Load ggplot2
library(ggplot2)

# Plot x2 vs. x1, colored by y
scatter_plot<- ggplot(data = data, aes(x = x1, y = x4, color = wt5
                                       
                              )) + 
    # Add a point layer
    geom_point() + 
    scale_color_manual(values = c("red", "blue")) +
    # Specify equal coordinates
    coord_equal()
 
scatter_plot  
```

```{R}
testdf <- data.frame(x2,x1,data$MillionYes)
print(testdf)

```

```{r}
install.packages("e1071")
library(e1071)

```

```{r}

# Print average accuracy and standard deviation
accuracy <- rep(NA, 1)
set.seed(2)

# Calculate accuracies for 100 training/test partitions
for (i in 1:1){
    testdf[, "train"] <- ifelse(runif(nrow(testdf)) < 0.8, 1, 0)
    trainset <- testdf[testdf$train == 1, ]
    testset <- testdf[testdf$train == 0, ]
    trainColNum <- grep("train", names(trainset))
    trainset <- trainset[, -trainColNum]
    testset <- testset[, -trainColNum]
    svm_model <- svm(data.MillionYes ~ ., data = trainset, type = "C-classification", kernel = "linear")
    pred_test <- predict(svm_model, testset)
    accuracy[i] <- mean(pred_test == testset$data.MillionYes)
}

# Print average accuracy and standard deviation
mean(accuracy)
sd(accuracy)



```
```{r}
plot(svm_model,testset)
```



```{r}

# Print average accuracy and standard deviation
accuracy <- rep(NA, 10)
set.seed(2)

# Calculate accuracies for 100 training/test partitions
for (i in 1:10){
    testdf[, "train"] <- ifelse(runif(nrow(testdf)) < 0.8, 1, 0)
    trainset <- testdf[testdf$train == 1, ]
    testset <- testdf[testdf$train == 0, ]
    trainColNum <- grep("train", names(trainset))
    trainset <- trainset[, -trainColNum]
    testset <- testset[, -trainColNum]
    svm_model <- svm(data.MillionYes ~ ., data = trainset, type = "C-classification", kernel = "radial")
    pred_test <- predict(svm_model, testset)
    accuracy[i] <- mean(pred_test == testset$data.MillionYes)
}

# Print average accuracy and standard deviation
mean(accuracy)
sd(accuracy)



```

```{r}
plot(svm_model,testset)
```




